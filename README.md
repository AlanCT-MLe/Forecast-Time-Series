# â³ Time Series Labs

<img src="banner.png" alt="drawing" width="400"/>

## ğŸ“Œ 1. Introduction
This repository contains four lab assignments from a graduate-level **Time Series Analysis and Machine Learning** course at LinkÃ¶ping University.
Each lab focuses on different aspects of modeling, analyzing, and predicting time series data, ranging from **classical statistical methods** to **deep learning approaches**.  
The labs progressively build an understanding of time series fundamentals, linear models, state-space representations, and recurrent neural networks.

---

## âš™ï¸ 2. Requirements
All labs are implemented in **Python** using Jupyter notebooks.  
The following libraries are used throughout the assignments:

- ğŸ§® `numpy`  
- ğŸ“Š `pandas`  
- ğŸ“ˆ `matplotlib`  
- ğŸ”¬ `scipy`  
- ğŸ“‰ `statsmodels`  
- ğŸ¤– `tensorflow` / `keras`

## ğŸ“˜ 3. [Lab 1](https://github.com/AlanCT-MLe/Forecast-Time-Series/blob/main/Lab1/tssl_lab1.ipynb) â€“ Autoregressive Models and Forecasting

- **ğŸ¯ Objective**: Introduce autoregressive (AR) models for time series and their properties.  
- **ğŸ“‚ Content**:  
  - Exploratory analysis of stationary vs. non-stationary data.  
  - Model identification and order selection using ACF/PACF plots.  
  - Parameter estimation via least squares.  
  - One-step and multi-step forecasting.  
- **ğŸ› ï¸ Key skills**: Building AR models, interpreting autocorrelation, performing rolling forecasts.  

---

## ğŸ“— 4. Lab 2 â€“ ARMA and ARIMA Models

- **ğŸ¯ Objective**: Extend autoregressive modeling with moving average components, leading to ARMA and ARIMA models.  
- **ğŸ“‚ Content**:  
  - Simulation of ARMA processes.  
  - Estimation and fitting of ARMA models on real data.  
  - Differencing techniques for non-stationary time series.  
  - Forecasting with ARIMA models.  
- **ğŸ› ï¸ Key skills**: ARMA/ARIMA modeling, stationarity transformations, practical forecasting applications.  

---

## ğŸ“™ 5. Lab 3 â€“ State-Space Models and the Kalman Filter

- **ğŸ¯ Objective**: Explore state-space representations of time series and filtering techniques.  
- **ğŸ“‚ Content**:  
  - Formulating time series problems as linear state-space models.  
  - Implementing the **Kalman filter** for recursive estimation.  
  - Smoothing and prediction using the filter.  
  - Applications to tracking and noisy signal reconstruction.  
- **ğŸ› ï¸ Key skills**: State-space modeling, recursive filtering, handling hidden states in time series.  

---

## ğŸ“• 6. Lab 4 â€“ Recurrent Neural Networks

- **ğŸ¯ Objective**: Apply deep learning methods, particularly recurrent neural networks (RNNs), to time series prediction.  
- **ğŸ“‚ Content**:  
  - Baseline forecasting methods (naÃ¯ve and AR models).  
  - Implementation of Simple RNNs in Keras.  
  - Training strategies: full-sequence training, random windowing, and stateful sequential windowing.  
  - Comparison of predictive performance with classical models.  
  - Extension to more complex stacked RNN and LSTM architectures.  
- **ğŸ› ï¸ Key skills**: RNN modeling, sequential data training strategies, neural network implementation for time series.  

---

## ğŸš€ 7. Showcased Skills

Across these four labs, the repository demonstrates proficiency in:

- ğŸ“Š **Classical statistical modeling**: AR, ARMA, ARIMA models.  
- ğŸ”® **Forecasting techniques**: One-step and multi-step prediction.  
- ğŸ›°ï¸ **State-space methods**: Kalman filter and smoothing.  
- ğŸ¤– **Deep learning for time series**: RNNs, LSTMs, training strategies.  
- ğŸ **Practical implementation**: Python, NumPy, pandas, matplotlib, TensorFlow/Keras.  
- ğŸ§  **Analytical thinking**: Evaluating models with MSE/MAE, handling stationarity, and understanding temporal dependencies.  

